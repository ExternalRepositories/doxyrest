<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.13">
  <compounddef id="libusb_mtasync" kind="page">
    <compoundname>libusb_mtasync</compoundname>
    <title>Multi-threaded applications and asynchronous I/O</title>
    <detaileddescription>
<para>libusb is a thread-safe library, but extra considerations must be applied to applications which interact with libusb from multiple threads.</para><para>The underlying issue that must be addressed is that all libusb I/O revolves around monitoring file descriptors through the poll()/select() system calls. This is directly exposed at the <ref refid="group__libusb__asyncio" kindref="compound">asynchronous interface</ref> but it is important to note that the <ref refid="group__libusb__syncio" kindref="compound">synchronous interface</ref> is implemented on top of the asynchonrous interface, therefore the same considerations apply.</para><para>The issue is that if two or more threads are concurrently calling poll() or select() on libusb&apos;s file descriptors then only one of those threads will be woken up when an event arrives. The others will be completely oblivious that anything has happened.</para><para>Consider the following pseudo-code, which submits an asynchronous transfer then waits for its completion. This style is one way you could implement a synchronous interface on top of the asynchronous interface (and libusb does something similar, albeit more advanced due to the complications explained on this page).</para><para><programlisting><codeline><highlight class="normal">void<sp/>cb(struct<sp/>libusb_transfer<sp/>*transfer)</highlight></codeline>
<codeline><highlight class="normal">{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>int<sp/>*completed<sp/>=<sp/>transfer-&gt;user_data;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/>*completed<sp/>=<sp/>1;</highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">void<sp/>myfunc()<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>struct<sp/>libusb_transfer<sp/>*transfer;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>unsigned<sp/>char<sp/>buffer[LIBUSB_CONTROL_SETUP_SIZE]<sp/>__attribute__<sp/>((aligned<sp/>(2)));</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>int<sp/>completed<sp/>=<sp/>0;</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>transfer<sp/>=<sp/>libusb_alloc_transfer(0);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_fill_control_setup(buffer,</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>LIBUSB_REQUEST_TYPE_VENDOR<sp/>|<sp/>LIBUSB_ENDPOINT_OUT,<sp/>0x04,<sp/>0x01,<sp/>0,<sp/>0);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_fill_control_transfer(transfer,<sp/>dev,<sp/>buffer,<sp/>cb,<sp/>&amp;completed,<sp/>1000);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_submit_transfer(transfer);</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>while<sp/>(!completed)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>poll(libusb<sp/>file<sp/>descriptors,<sp/>120*1000);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>if<sp/>(poll<sp/>indicates<sp/>activity)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>libusb_handle_events_timeout(ctx,<sp/>&amp;zero_tv);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>printf(&quot;completed!&quot;);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>//<sp/>other<sp/>code<sp/>here</highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
</programlisting></para><para>Here we are <emphasis>serializing</emphasis> completion of an asynchronous event against a condition - the condition being completion of a specific transfer. The poll() loop has a long timeout to minimize CPU usage during situations when nothing is happening (it could reasonably be unlimited).</para><para>If this is the only thread that is polling libusb&apos;s file descriptors, there is no problem: there is no danger that another thread will swallow up the event that we are interested in. On the other hand, if there is another thread polling the same descriptors, there is a chance that it will receive the event that we were interested in. In this situation, <computeroutput>myfunc()</computeroutput> will only realise that the transfer has completed on the next iteration of the loop, <emphasis>up to 120 seconds later.</emphasis> Clearly a two-minute delay is undesirable, and don&apos;t even think about using short timeouts to circumvent this issue!</para><para>The solution here is to ensure that no two threads are ever polling the file descriptors at the same time. A naive implementation of this would impact the capabilities of the library, so libusb offers the scheme documented below to ensure no loss of functionality.</para><para>Before we go any further, it is worth mentioning that all libusb-wrapped event handling procedures fully adhere to the scheme documented below. This includes <ref refid="group__libusb__poll_1ga4989086e3f0327f3886a4c474ec7c327" kindref="member">libusb_handle_events()</ref> and its variants, and all the synchronous I/O functions - libusb hides this headache from you.</para><sect1 id="libusb_mtasync_1Using">
<title>libusb_handle_events() from multiple threads</title>
<para>Even when only using <ref refid="group__libusb__poll_1ga4989086e3f0327f3886a4c474ec7c327" kindref="member">libusb_handle_events()</ref> and synchronous I/O functions, you can still have a race condition. You might be tempted to solve the above with <ref refid="group__libusb__poll_1ga4989086e3f0327f3886a4c474ec7c327" kindref="member">libusb_handle_events()</ref> like so:</para><para><programlisting><codeline><highlight class="normal">libusb_submit_transfer(transfer);</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">while<sp/>(!completed)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_handle_events(ctx);</highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
<codeline><highlight class="normal">printf(&quot;completed!&quot;);</highlight></codeline>
</programlisting></para><para>This however has a race between the checking of completed and <ref refid="group__libusb__poll_1ga4989086e3f0327f3886a4c474ec7c327" kindref="member">libusb_handle_events()</ref> acquiring the events lock, so another thread could have completed the transfer, resulting in this thread hanging until either a timeout or another event occurs. See also commit 6696512aade99bb15d6792af90ae329af270eba6 which fixes this in the synchronous API implementation of libusb.</para><para>Fixing this race requires checking the variable completed only after taking the event lock, which defeats the concept of just calling <ref refid="group__libusb__poll_1ga4989086e3f0327f3886a4c474ec7c327" kindref="member">libusb_handle_events()</ref> without worrying about locking. This is why libusb-1.0.9 introduces the new <ref refid="group__libusb__poll_1ga43e52b912a760b41a0cf8a4a472fbd5b" kindref="member">libusb_handle_events_timeout_completed()</ref> and <ref refid="group__libusb__poll_1ga0bc99f39e4cf5ad393cd5936c36037d1" kindref="member">libusb_handle_events_completed()</ref> functions, which handles doing the completion check for you after they have acquired the lock:</para><para><programlisting><codeline><highlight class="normal">libusb_submit_transfer(transfer);</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal">while<sp/>(!completed)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_handle_events_completed(ctx,<sp/>&amp;completed);</highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
<codeline><highlight class="normal">printf(&quot;completed!&quot;);</highlight></codeline>
</programlisting></para><para>This nicely fixes the race in our example. Note that if all you want to do is submit a single transfer and wait for its completion, then using one of the synchronous I/O functions is much easier.</para></sect1>
<sect1 id="libusb_mtasync_1eventlock">
<title>The events lock</title>
<para>The problem is when we consider the fact that libusb exposes file descriptors to allow for you to integrate asynchronous USB I/O into existing main loops, effectively allowing you to do some work behind libusb&apos;s back. If you do take libusb&apos;s file descriptors and pass them to poll()/select() yourself, you need to be aware of the associated issues.</para><para>The first concept to be introduced is the events lock. The events lock is used to serialize threads that want to handle events, such that only one thread is handling events at any one time.</para><para>You must take the events lock before polling libusb file descriptors, using <ref refid="group__libusb__poll_1gaa72153938dc4f34decfacbc6cc6237ef" kindref="member">libusb_lock_events()</ref>. You must release the lock as soon as you have aborted your poll()/select() loop, using <ref refid="group__libusb__poll_1gacefbeabdd3409490dc4678f00779c165" kindref="member">libusb_unlock_events()</ref>.</para></sect1>
<sect1 id="libusb_mtasync_1threadwait">
<title>Letting other threads do the work for you</title>
<para>Although the events lock is a critical part of the solution, it is not enough on it&apos;s own. You might wonder if the following is sufficient... <programlisting><codeline><highlight class="normal">libusb_lock_events(ctx);</highlight></codeline>
<codeline><highlight class="normal">while<sp/>(!completed)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>poll(libusb<sp/>file<sp/>descriptors,<sp/>120*1000);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>if<sp/>(poll<sp/>indicates<sp/>activity)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>libusb_handle_events_timeout(ctx,<sp/>&amp;zero_tv);</highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
<codeline><highlight class="normal">libusb_unlock_events(ctx);</highlight></codeline>
</programlisting> ...and the answer is that it is not. This is because the transfer in the code shown above may take a long time (say 30 seconds) to complete, and the lock is not released until the transfer is completed.</para><para>Another thread with similar code that wants to do event handling may be working with a transfer that completes after a few milliseconds. Despite having such a quick completion time, the other thread cannot check that status of its transfer until the code above has finished (30 seconds later) due to contention on the lock.</para><para>To solve this, libusb offers you a mechanism to determine when another thread is handling events. It also offers a mechanism to block your thread until the event handling thread has completed an event (and this mechanism does not involve polling of file descriptors).</para><para>After determining that another thread is currently handling events, you obtain the <emphasis>event waiters</emphasis> lock using <ref refid="group__libusb__poll_1ga150865a3f35c38173d688efa7ee52929" kindref="member">libusb_lock_event_waiters()</ref>. You then re-check that some other thread is still handling events, and if so, you call <ref refid="group__libusb__poll_1gae22755d523560be2867be7d09034ca50" kindref="member">libusb_wait_for_event()</ref>.</para><para><ref refid="group__libusb__poll_1gae22755d523560be2867be7d09034ca50" kindref="member">libusb_wait_for_event()</ref> puts your application to sleep until an event occurs, or until a thread releases the events lock. When either of these things happen, your thread is woken up, and should re-check the condition it was waiting on. It should also re-check that another thread is handling events, and if not, it should start handling events itself.</para><para>This looks like the following, as pseudo-code: <programlisting><codeline><highlight class="normal">retry:</highlight></codeline>
<codeline><highlight class="normal">if<sp/>(libusb_try_lock_events(ctx)<sp/>==<sp/>0)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>//<sp/>we<sp/>obtained<sp/>the<sp/>event<sp/>lock:<sp/>do<sp/>our<sp/>own<sp/>event<sp/>handling</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>while<sp/>(!completed)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>if<sp/>(!libusb_event_handling_ok(ctx))<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>libusb_unlock_events(ctx);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>goto<sp/>retry;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>poll(libusb<sp/>file<sp/>descriptors,<sp/>120*1000);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>if<sp/>(poll<sp/>indicates<sp/>activity)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>libusb_handle_events_locked(ctx,<sp/>0);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_unlock_events(ctx);</highlight></codeline>
<codeline><highlight class="normal">}<sp/>else<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>//<sp/>another<sp/>thread<sp/>is<sp/>doing<sp/>event<sp/>handling.<sp/>wait<sp/>for<sp/>it<sp/>to<sp/>signal<sp/>us<sp/>that</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>//<sp/>an<sp/>event<sp/>has<sp/>completed</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_lock_event_waiters(ctx);</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>while<sp/>(!completed)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>//<sp/>now<sp/>that<sp/>we<sp/>have<sp/>the<sp/>event<sp/>waiters<sp/>lock,<sp/>double<sp/>check<sp/>that<sp/>another</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>//<sp/>thread<sp/>is<sp/>still<sp/>handling<sp/>events<sp/>for<sp/>us.<sp/>(it<sp/>may<sp/>have<sp/>ceased<sp/>handling</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>//<sp/>events<sp/>in<sp/>the<sp/>time<sp/>it<sp/>took<sp/>us<sp/>to<sp/>reach<sp/>this<sp/>point)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>if<sp/>(!libusb_event_handler_active(ctx))<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>//<sp/>whoever<sp/>was<sp/>handling<sp/>events<sp/>is<sp/>no<sp/>longer<sp/>doing<sp/>so,<sp/>try<sp/>again</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>libusb_unlock_event_waiters(ctx);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>goto<sp/>retry;</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>libusb_wait_for_event(ctx,<sp/>NULL);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/>libusb_unlock_event_waiters(ctx);</highlight></codeline>
<codeline><highlight class="normal">}</highlight></codeline>
<codeline><highlight class="normal">printf(&quot;completed!\n&quot;);</highlight></codeline>
</programlisting></para><para>A naive look at the above code may suggest that this can only support one event waiter (hence a total of 2 competing threads, the other doing event handling), because the event waiter seems to have taken the event waiters lock while waiting for an event. However, the system does support multiple event waiters, because <ref refid="group__libusb__poll_1gae22755d523560be2867be7d09034ca50" kindref="member">libusb_wait_for_event()</ref> actually drops the lock while waiting, and reaquires it before continuing.</para><para>We have now implemented code which can dynamically handle situations where nobody is handling events (so we should do it ourselves), and it can also handle situations where another thread is doing event handling (so we can piggyback onto them). It is also equipped to handle a combination of the two, for example, another thread is doing event handling, but for whatever reason it stops doing so before our condition is met, so we take over the event handling.</para><para>Four functions were introduced in the above pseudo-code. Their importance should be apparent from the code shown above.<orderedlist>
<listitem><para><ref refid="group__libusb__poll_1ga6e5a116d5c9498ca4a0e29587fec1a05" kindref="member">libusb_try_lock_events()</ref> is a non-blocking function which attempts to acquire the events lock but returns a failure code if it is contended.</para></listitem><listitem><para><ref refid="group__libusb__poll_1ga63592b28c265185d9469d1e6920d8373" kindref="member">libusb_event_handling_ok()</ref> checks that libusb is still happy for your thread to be performing event handling. Sometimes, libusb needs to interrupt the event handler, and this is how you can check if you have been interrupted. If this function returns 0, the correct behaviour is for you to give up the event handling lock, and then to repeat the cycle. The following <ref refid="group__libusb__poll_1ga6e5a116d5c9498ca4a0e29587fec1a05" kindref="member">libusb_try_lock_events()</ref> will fail, so you will become an events waiter. For more information on this, read <ref refid="libusb_mtasync_1fullstory" kindref="member">The full story</ref> below.</para></listitem><listitem><para><ref refid="group__libusb__poll_1ga71da081f97afa3bf68aed8e372254e8f" kindref="member">libusb_handle_events_locked()</ref> is a variant of <ref refid="group__libusb__poll_1ga6deff4c7d3a6c04bb9ec9fd259b48933" kindref="member">libusb_handle_events_timeout()</ref> that you can call while holding the events lock. <ref refid="group__libusb__poll_1ga6deff4c7d3a6c04bb9ec9fd259b48933" kindref="member">libusb_handle_events_timeout()</ref> itself implements similar logic to the above, so be sure not to call it when you are &quot;working behind libusb&apos;s back&quot;, as is the case here.</para></listitem><listitem><para><ref refid="group__libusb__poll_1ga3a0a6e8be310c20f1ca68722149f9dbf" kindref="member">libusb_event_handler_active()</ref> determines if someone is currently holding the events lock</para></listitem></orderedlist>
</para><para>You might be wondering why there is no function to wake up all threads blocked on <ref refid="group__libusb__poll_1gae22755d523560be2867be7d09034ca50" kindref="member">libusb_wait_for_event()</ref>. This is because libusb can do this internally: it will wake up all such threads when someone calls <ref refid="group__libusb__poll_1gacefbeabdd3409490dc4678f00779c165" kindref="member">libusb_unlock_events()</ref> or when a transfer completes (at the point after its callback has returned).</para><sect2 id="libusb_mtasync_1fullstory">
<title>The full story</title>
<para>The above explanation should be enough to get you going, but if you&apos;re really thinking through the issues then you may be left with some more questions regarding libusb&apos;s internals. If you&apos;re curious, read on, and if not, skip to the next section to avoid confusing yourself!</para><para>The immediate question that may spring to mind is: what if one thread modifies the set of file descriptors that need to be polled while another thread is doing event handling?</para><para>There are 2 situations in which this may happen.<orderedlist>
<listitem><para><ref refid="group__libusb__dev_1ga3f184a8be4488a767b2e0ae07e76d1b0" kindref="member">libusb_open()</ref> will add another file descriptor to the poll set, therefore it is desirable to interrupt the event handler so that it restarts, picking up the new descriptor.</para></listitem><listitem><para><ref refid="group__libusb__dev_1ga779bc4f1316bdb0ac383bddbd538620e" kindref="member">libusb_close()</ref> will remove a file descriptor from the poll set. There are all kinds of race conditions that could arise here, so it is important that nobody is doing event handling at this time.</para></listitem></orderedlist>
</para><para>libusb handles these issues internally, so application developers do not have to stop their event handlers while opening/closing devices. Here&apos;s how it works, focusing on the <ref refid="group__libusb__dev_1ga779bc4f1316bdb0ac383bddbd538620e" kindref="member">libusb_close()</ref> situation first:</para><para><orderedlist>
<listitem><para>During initialization, libusb opens an internal pipe, and it adds the read end of this pipe to the set of file descriptors to be polled.</para></listitem><listitem><para>During <ref refid="group__libusb__dev_1ga779bc4f1316bdb0ac383bddbd538620e" kindref="member">libusb_close()</ref>, libusb writes some dummy data on this event pipe. This immediately interrupts the event handler. libusb also records internally that it is trying to interrupt event handlers for this high-priority event.</para></listitem><listitem><para>At this point, some of the functions described above start behaving differently:<itemizedlist>
<listitem><para><ref refid="group__libusb__poll_1ga63592b28c265185d9469d1e6920d8373" kindref="member">libusb_event_handling_ok()</ref> starts returning 1, indicating that it is NOT OK for event handling to continue.</para></listitem><listitem><para><ref refid="group__libusb__poll_1ga6e5a116d5c9498ca4a0e29587fec1a05" kindref="member">libusb_try_lock_events()</ref> starts returning 1, indicating that another thread holds the event handling lock, even if the lock is uncontended.</para></listitem><listitem><para><ref refid="group__libusb__poll_1ga3a0a6e8be310c20f1ca68722149f9dbf" kindref="member">libusb_event_handler_active()</ref> starts returning 1, indicating that another thread is doing event handling, even if that is not true.</para></listitem></itemizedlist>
</para></listitem><listitem><para>The above changes in behaviour result in the event handler stopping and giving up the events lock very quickly, giving the high-priority <ref refid="group__libusb__dev_1ga779bc4f1316bdb0ac383bddbd538620e" kindref="member">libusb_close()</ref> operation a &quot;free ride&quot; to acquire the events lock. All threads that are competing to do event handling become event waiters.</para></listitem><listitem><para>With the events lock held inside <ref refid="group__libusb__dev_1ga779bc4f1316bdb0ac383bddbd538620e" kindref="member">libusb_close()</ref>, libusb can safely remove a file descriptor from the poll set, in the safety of knowledge that nobody is polling those descriptors or trying to access the poll set.</para></listitem><listitem><para>After obtaining the events lock, the close operation completes very quickly (usually a matter of milliseconds) and then immediately releases the events lock.</para></listitem><listitem><para>At the same time, the behaviour of <ref refid="group__libusb__poll_1ga63592b28c265185d9469d1e6920d8373" kindref="member">libusb_event_handling_ok()</ref> and friends reverts to the original, documented behaviour.</para></listitem><listitem><para>The release of the events lock causes the threads that are waiting for events to be woken up and to start competing to become event handlers again. One of them will succeed; it will then re-obtain the list of poll descriptors, and USB I/O will then continue as normal.</para></listitem></orderedlist>
</para><para><ref refid="group__libusb__dev_1ga3f184a8be4488a767b2e0ae07e76d1b0" kindref="member">libusb_open()</ref> is similar, and is actually a more simplistic case. Upon a call to <ref refid="group__libusb__dev_1ga3f184a8be4488a767b2e0ae07e76d1b0" kindref="member">libusb_open()</ref>:</para><para><orderedlist>
<listitem><para>The device is opened and a file descriptor is added to the poll set.</para></listitem><listitem><para>libusb sends some dummy data on the event pipe, and records that it is trying to modify the poll descriptor set.</para></listitem><listitem><para>The event handler is interrupted, and the same behaviour change as for <ref refid="group__libusb__dev_1ga779bc4f1316bdb0ac383bddbd538620e" kindref="member">libusb_close()</ref> takes effect, causing all event handling threads to become event waiters.</para></listitem><listitem><para>The <ref refid="group__libusb__dev_1ga3f184a8be4488a767b2e0ae07e76d1b0" kindref="member">libusb_open()</ref> implementation takes its free ride to the events lock.</para></listitem><listitem><para>Happy that it has successfully paused the events handler, <ref refid="group__libusb__dev_1ga3f184a8be4488a767b2e0ae07e76d1b0" kindref="member">libusb_open()</ref> releases the events lock.</para></listitem><listitem><para>The event waiter threads are all woken up and compete to become event handlers again. The one that succeeds will obtain the list of poll descriptors again, which will include the addition of the new device.</para></listitem></orderedlist>
</para></sect2>
<sect2 id="libusb_mtasync_1concl">
<title>Closing remarks</title>
<para>The above may seem a little complicated, but hopefully I have made it clear why such complications are necessary. Also, do not forget that this only applies to applications that take libusb&apos;s file descriptors and integrate them into their own polling loops.</para><para>You may decide that it is OK for your multi-threaded application to ignore some of the rules and locks detailed above, because you don&apos;t think that two threads can ever be polling the descriptors at the same time. If that is the case, then that&apos;s good news for you because you don&apos;t have to worry. But be careful here; remember that the synchronous I/O functions do event handling internally. If you have one thread doing event handling in a loop (without implementing the rules and locking semantics documented above) and another trying to send a synchronous USB transfer, you will end up with two threads monitoring the same descriptors, and the above-described undesirable behaviour occurring. The solution is for your polling thread to play by the rules; the synchronous I/O functions do so, and this will result in them getting along in perfect harmony.</para><para>If you do have a dedicated thread doing event handling, it is perfectly legal for it to take the event handling lock for long periods of time. Any synchronous I/O functions you call from other threads will transparently fall back to the &quot;event waiters&quot; mechanism detailed above. The only consideration that your event handling thread must apply is the one related to <ref refid="group__libusb__poll_1ga63592b28c265185d9469d1e6920d8373" kindref="member">libusb_event_handling_ok()</ref>: you must call this before every poll(), and give up the events lock if instructed. </para></sect2>
</sect1>
    </detaileddescription>
  </compounddef>
</doxygen>
